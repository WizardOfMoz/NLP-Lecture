{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r3qrDRU42xN9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B5Itvs18jjS"
      },
      "source": [
        "##Extrinsic Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln1apOvqxPt1",
        "outputId": "001d4d92-ab3f-45db-f1a7-a91dc6278041"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import contractions\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "from nltk.corpus import stopwords,wordnet\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer,TreebankWordTokenizer\n",
        "from nltk.tokenize import wordpunct_tokenize,TweetTokenizer\n",
        "\n",
        "\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "\n",
        "from autocorrect import Speller\n",
        "spell = Speller(lang='en')\n",
        "def autospell(text):\n",
        "    spells = [spell(w) for w in (nltk.word_tokenize(text))]\n",
        "    return \" \".join(spells)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aPILRRJXxW0g"
      },
      "outputs": [],
      "source": [
        "def pos_tagger(tag):\n",
        "    nltk_tag=tag[1]\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV   \n",
        "    return 'n'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S1mbcP7bxZlH"
      },
      "outputs": [],
      "source": [
        "stop_list=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\\\n",
        "     'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \\\n",
        "     'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\\\n",
        "    'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'if', 'or', 'because', 'as', 'until','of', 'at', 'by', 'for', 'with', 'about', 'between',\\\n",
        "    'into', 'through', 'during', 'to', 'from','in', 'out','on','again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', \n",
        "    'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', \n",
        "    'just','should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y','u','im','go','will','come','whats','twitter','tweet',\\\n",
        "    'know','x','yeah','year','yet','youre','would','do','can','nan','see','look','one','could']\n",
        "\n",
        "stop_reg = r'\\b(?:'+'|'.join(stop_list)+r')\\b'\n",
        "stop_reg\n",
        "stopword_finder= re.compile(stop_reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "49rsEUp78zQB"
      },
      "outputs": [],
      "source": [
        "def processing(sentence, verbose=False):\n",
        "  og_sentence = sentence\n",
        "  sentence=sentence.lower()#CASE FOLDING\n",
        "  html_finder = re.compile(r'<.*?>|&\\w+;')\n",
        "  rmhtml_Text=html_finder.sub('',sentence)  #remove HTML Tags\n",
        "  # rmurl_Text = re.sub(r'http\\S+|https:\\S+|www\\S+|.com\\S+', '', rmhtml_Text) #remove URL tags\n",
        "  pre_url = r'(?:https?://)|(?:www\\.)'\n",
        "  url_set = r'[\\w+=?/._\\-:;&*^$#@~`!|]'\n",
        "  rmurl_Text=re.sub(f'(?:{pre_url}){url_set}+|{url_set}+\\.com{url_set}*', '',rmhtml_Text)\n",
        "  username_finder = re.compile('@\\w+')\n",
        "  rmurl_Text=username_finder.sub('',rmurl_Text) #remove usernames\n",
        "  rmwhite_Text=re.sub(' +', ' ',rmurl_Text) #remove extra whitespace\n",
        "  rmwhite_Text = contractions.fix(rmwhite_Text) #Remove contractions\n",
        "  rmpunt_text=re.sub('[^\\w\\s]','',rmwhite_Text) #punctuation and username removal\n",
        "  \n",
        "  token_text=[token for token in TweetTokenizer().tokenize(rmpunt_text)]#tokenize text \n",
        "  \n",
        "  # stem_text= [stemmer.stem(word) for word in rmpunt_text]#stemming\n",
        "  pos_tags=[pos_tagger(tag) for tag in nltk.pos_tag(token_text)]\n",
        "  lem_text= [lemmatizer.lemmatize(word,pos=pos) for word,pos in zip(token_text,pos_tags)] #lemmatize word\n",
        "  # print(lem_text)\n",
        "  rmstop_text = [tok for tok in lem_text if not stopword_finder.search(tok)]\n",
        "  # print(rmstop_text)\n",
        "  # if len(rmstop_text)==0:\n",
        "  #   rmstop_text=['<s>','</s>']\n",
        "  # if rmstop_text[0]!='<s>':\n",
        "  #   rmstop_text.insert('<s>',0)\n",
        "  # if rmstop_text[-1]!='</s>':\n",
        "  #   rmstop_text.append('</s>')\n",
        "  \n",
        "  sentence=TreebankWordDetokenizer().detokenize(rmstop_text) #convert to sentence \n",
        "  spell_sentence = autospell(sentence)\n",
        "  if verbose:\n",
        "    print(f'Original sentence :\\n{og_sentence}\\n')\n",
        "    print(f'Removing HTML and (Lowercasing):\\n{rmhtml_Text}\\n')\n",
        "    print(f'Removing URL tags (and usernames):\\n{rmurl_Text}\\n')\n",
        "    print(f'Removing whitespace(and expand contractions):\\n{rmwhite_Text}\\n')\n",
        "    print(f'Remove punctuations:\\n{rmpunt_text}\\n')   \n",
        "    print(f'Tokenize Text:\\n{token_text}\\n')\n",
        "    print(f'Lemmatize Text:\\n{lem_text}\\n')\n",
        "    print(f'Removing stop words Text:\\n{rmstop_text}\\n')\n",
        "    print(f'Spelling Correction:\\n{spell_sentence}\\n')\n",
        "  \n",
        "  return spell_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cvEipCDM8mcp"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "def train_and_evaluate(train_sentences, train_labels,\n",
        "test_sentences, test_labels):\n",
        "  '''\n",
        "  parameters:\n",
        "  train_sentences : list of training sentences\n",
        "  train_labels : list of training labels\n",
        "  test_sentences : list of test sentences\n",
        "  test_labels : list of test labels\n",
        "  output:\n",
        "  accuracy : accuracy of the test set\n",
        "  '''\n",
        "  # Model building\n",
        "  model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "  # Training the model with the training data\n",
        "  model.fit(train_sentences, train_labels)\n",
        "  # Predicting the test data categories\n",
        "  predicted_test_labels = model.predict(test_sentences)\n",
        "  return accuracy_score(test_labels, predicted_test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zm-ICNTQRKGZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "df=pd.read_csv('/content/drive/MyDrive/NLP Assignments/A1_dataset_processed.csv')\n",
        "#train sentences to list\n",
        "train_sent_A= df.NEW_TEXT.values.astype('U').tolist()\n",
        "#train labels to list\n",
        "train_labels_A=df['LABEL'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kq1Fb0zCYaP8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('combined_data_.csv')\n",
        "#train sentences to list\n",
        "train_sent_B2= df.TEXT.values.astype('U').tolist()\n",
        "#train labels to list\n",
        "train_labels_B2=df['LABEL'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2sqWvlE1-a0H"
      },
      "outputs": [],
      "source": [
        "# df=pd.read_csv('/content/drive/MyDrive/NLP Assignments/A1_dataset_processed.csv') #modify this for dataset B\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP Assignments/combined_data.csv')\n",
        "#train sentences to list\n",
        "train_sent_B1= df.TEXT.values.astype('U').tolist()\n",
        "#train labels to list\n",
        "train_labels_B1=df['LABEL'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BxInHFhDNxoS"
      },
      "outputs": [],
      "source": [
        "#read test csv\n",
        "test_df=pd.read_csv('/content/drive/MyDrive/NLP Assignments/A2_test_dataset.csv')\n",
        "#pre-process test data\n",
        "data=test_df.apply(lambda row: processing(row.TEXT,verbose=False),axis=1)\n",
        "test_df['NEW_TEXT']= data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qTnRG1k4-_Uq"
      },
      "outputs": [],
      "source": [
        "#test sentences to list\n",
        "test_sent=test_df['NEW_TEXT'].values.astype('U').tolist()\n",
        "#test labels to list\n",
        "test_labels=test_df['LABEL'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUqVvnR8RGBj",
        "outputId": "576ff21c-5bd9-4de3-e221-33cf2f83194a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of Test set using dataset A for training is :0.8509316770186336\n"
          ]
        }
      ],
      "source": [
        "print(f'The accuracy of Test set using dataset A for training is :{train_and_evaluate(train_sent_A,train_labels_A,test_sent,test_labels)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY3v6ILGNFWE",
        "outputId": "04429741-1e60-4955-a506-0e20bf81ad12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of Test set using dataset B for training is :0.8804347826086957\n"
          ]
        }
      ],
      "source": [
        "print(f'The accuracy of Test set using dataset B for training is :{train_and_evaluate(train_sent_B2,train_labels_B2,test_sent,test_labels)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE9OEMlTM0jt",
        "outputId": "56cb720c-91b3-451f-bf4e-5c11f593a39f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of Test set using dataset B for training is :0.8913043478260869\n"
          ]
        }
      ],
      "source": [
        "print(f'The accuracy of Test set using dataset B for training is :{train_and_evaluate(train_sent_B1,train_labels_B1,test_sent,test_labels)}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9a6X8d5GW-KV"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
